#!/usr/bin/env python3
"""
ç»“æžœåˆå¹¶æ¨¡å—
Result Merger Module

åˆå¹¶å¹¶è¡Œå¤„ç†çš„æå–ç»“æžœ
Merge extraction results from parallel processing
"""

import os
import json
import pandas as pd
from pathlib import Path
from typing import List, Dict, Any, Optional
from openpyxl import Workbook, load_workbook
from openpyxl.styles import PatternFill, Alignment, Font

try:
    from i18n.i18n_manager import get_message
except ImportError:
    def get_message(key, **kwargs):
        return key.format(**kwargs) if kwargs else key


class ResultMerger:
    """ç»“æžœåˆå¹¶å™¨ / Result Merger"""
    
    def __init__(self):
        self.merged_data = {}
        self.total_documents_processed = 0
        self.processing_stats = {}
    
    def merge_batch_results(self, temp_dir: str, config: Dict[str, Any]) -> str:
        """åˆå¹¶æ‰¹æ¬¡ç»“æžœ"""
        try:
            # æŸ¥æ‰¾æ‰€æœ‰æ‰¹æ¬¡ç»“æžœæ–‡ä»¶
            batch_files = list(Path(temp_dir).glob("batch_*_results.xlsx"))
            
            if not batch_files:
                raise Exception("No batch result files found")
            
            print(f"Found {len(batch_files)} batch result files")
            
            # åˆå§‹åŒ–åˆå¹¶æ•°æ®ç»“æž„
            self._initialize_merge_structure()
            
            # é€ä¸ªå¤„ç†æ‰¹æ¬¡æ–‡ä»¶
            for batch_file in batch_files:
                self._merge_single_batch(batch_file)
            
            # ä¿å­˜åˆå¹¶ç»“æžœ
            output_path = self._save_merged_results(config)
            
            # ç”Ÿæˆå¤„ç†ç»Ÿè®¡æŠ¥å‘Š
            self._generate_processing_report(output_path, config)
            
            return output_path
            
        except Exception as e:
            raise Exception(f"Failed to merge results: {str(e)}")
    
    def _initialize_merge_structure(self):
        """åˆå§‹åŒ–åˆå¹¶æ•°æ®ç»“æž„"""
        # åŸºäºŽæ•°æ®æå–çš„è¡¨ç»“æž„åˆå§‹åŒ–
        self.merged_data = {
            "Study_Info": [],
            "Groups": [],
            "Participant_Characteristics": [], 
            "Outcomes": [],
            "Results": [],
            "Comparisons": []
        }
        self.total_documents_processed = 0
        self.processing_stats = {
            "successful_extractions": 0,
            "failed_extractions": 0,
            "total_tables_extracted": 0,
            "processing_start_time": None,
            "processing_end_time": None
        }
    
    def _merge_single_batch(self, batch_file: Path):
        """åˆå¹¶å•ä¸ªæ‰¹æ¬¡æ–‡ä»¶"""
        try:
            # è¯»å–Excelæ–‡ä»¶çš„æ‰€æœ‰å·¥ä½œè¡¨
            excel_data = pd.read_excel(batch_file, sheet_name=None)
            
            # åˆå¹¶æ¯ä¸ªè¡¨çš„æ•°æ®
            for sheet_name, df in excel_data.items():
                if sheet_name in self.merged_data:
                    if not df.empty:
                        # å°†æ•°æ®æ¡†è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
                        records = df.to_dict('records')
                        self.merged_data[sheet_name].extend(records)
                        
                        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                        self.processing_stats["total_tables_extracted"] += 1
            
            # æ›´æ–°æ–‡æ¡£å¤„ç†è®¡æ•°
            if "Study_Info" in excel_data and not excel_data["Study_Info"].empty:
                self.total_documents_processed += len(excel_data["Study_Info"])
                self.processing_stats["successful_extractions"] += len(excel_data["Study_Info"])
            
            print(f"âœ“ Merged batch file: {batch_file.name}")
            
        except Exception as e:
            print(f"âœ— Failed to merge batch file {batch_file.name}: {e}")
            self.processing_stats["failed_extractions"] += 1
    
    def _save_merged_results(self, config: Dict[str, Any]) -> str:
        """ä¿å­˜åˆå¹¶ç»“æžœ"""
        try:
            # æž„å»ºè¾“å‡ºè·¯å¾„
            output_folder = config["paths"]["output_folder"]
            output_filename = config["paths"]["output_filename"]
            
            # åˆ›å»ºæŒ‰æ—¥æœŸç»„ç»‡çš„å­ç›®å½•ç»“æž„
            from datetime import datetime
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            date_folder = datetime.now().strftime("%Y-%m-%d")
            
            # åˆ›å»ºç»“æž„åŒ–çš„è¾“å‡ºç›®å½•
            structured_output_dir = os.path.join(output_folder, date_folder, "merged_results")
            Path(structured_output_dir).mkdir(parents=True, exist_ok=True)
            
            # æ·»åŠ æ—¶é—´æˆ³åˆ°æ–‡ä»¶å
            name_parts = output_filename.split('.')
            if len(name_parts) > 1:
                final_filename = f"{name_parts[0]}_merged_{timestamp}.{name_parts[1]}"
            else:
                final_filename = f"{output_filename}_merged_{timestamp}.xlsx"
            
            output_path = os.path.join(structured_output_dir, final_filename)
            
            # åˆ›å»ºExcelå·¥ä½œç°¿
            with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
                for sheet_name, data in self.merged_data.items():
                    if data:  # åªä¿å­˜éžç©ºçš„è¡¨
                        df = pd.DataFrame(data)
                        df.to_excel(writer, sheet_name=sheet_name, index=False)
                    else:
                        # åˆ›å»ºç©ºçš„å·¥ä½œè¡¨ä»¥ä¿æŒç»“æž„å®Œæ•´æ€§
                        empty_df = pd.DataFrame()
                        empty_df.to_excel(writer, sheet_name=sheet_name, index=False)
            
            # ç¾ŽåŒ–Excelæ ¼å¼
            self._format_excel_output(output_path)
            
            return output_path
            
        except Exception as e:
            raise Exception(f"Failed to save merged results: {str(e)}")
    
    def _format_excel_output(self, output_path: str):
        """æ ¼å¼åŒ–Excelè¾“å‡º"""
        try:
            workbook = load_workbook(output_path)
            
            # å®šä¹‰æ ·å¼
            header_fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
            header_font = Font(color="FFFFFF", bold=True)
            center_alignment = Alignment(horizontal="center", vertical="center")
            
            for sheet_name in workbook.sheetnames:
                worksheet = workbook[sheet_name]
                
                # æ ¼å¼åŒ–æ ‡é¢˜è¡Œ
                if worksheet.max_row > 0:
                    for cell in worksheet[1]:
                        cell.fill = header_fill
                        cell.font = header_font
                        cell.alignment = center_alignment
                
                # è‡ªåŠ¨è°ƒæ•´åˆ—å®½
                from openpyxl.utils import get_column_letter
                for col_index, column in enumerate(worksheet.columns, 1):
                    max_length = 0
                    
                    # ä½¿ç”¨get_column_letterå‡½æ•°å®‰å…¨åœ°èŽ·å–åˆ—å­—æ¯
                    column_letter = get_column_letter(col_index)
                    
                    for cell in column:
                        try:
                            # æ£€æŸ¥å•å…ƒæ ¼æ˜¯å¦ä¸ºåˆå¹¶å•å…ƒæ ¼
                            if hasattr(cell, 'value') and cell.value is not None:
                                cell_length = len(str(cell.value))
                                if cell_length > max_length:
                                    max_length = cell_length
                        except:
                            pass
                    
                    adjusted_width = min(max_length + 2, 50)  # æœ€å¤§å®½åº¦é™åˆ¶ä¸º50
                    worksheet.column_dimensions[column_letter].width = adjusted_width
            
            workbook.save(output_path)
            
        except Exception as e:
            print(f"Warning: Failed to format Excel output: {e}")
    
    def _generate_processing_report(self, output_path: str, config: Dict[str, Any]):
        """ç”Ÿæˆå¤„ç†ç»Ÿè®¡æŠ¥å‘Š"""
        try:
            report_data = {
                "æ€»å¤„ç†æ–‡æ¡£æ•°": self.total_documents_processed,
                "æˆåŠŸæå–": self.processing_stats["successful_extractions"],
                "å¤±è´¥æå–": self.processing_stats["failed_extractions"],
                "æå–çš„è¡¨æ ¼æ€»æ•°": self.processing_stats["total_tables_extracted"],
                "è¾“å‡ºæ–‡ä»¶": output_path
            }
            
            # è®¡ç®—å„è¡¨çš„è®°å½•æ•°
            for table_name, data in self.merged_data.items():
                report_data[f"{table_name}_è®°å½•æ•°"] = len(data)
            
            # å°†æŠ¥å‘Šä¿å­˜åˆ°åŒä¸€ç›®å½•ä¸‹çš„reportså­æ–‡ä»¶å¤¹
            output_dir = os.path.dirname(output_path)
            reports_dir = os.path.join(os.path.dirname(output_dir), "reports")
            Path(reports_dir).mkdir(parents=True, exist_ok=True)
            
            report_filename = os.path.basename(output_path).replace('.xlsx', '_processing_report.json')
            report_path = os.path.join(reports_dir, report_filename)
            
            with open(report_path, 'w', encoding='utf-8') as f:
                json.dump(report_data, f, indent=2, ensure_ascii=False)
            
            # æ‰“å°æ‘˜è¦
            try:
                from i18n.i18n_manager import get_message
            except ImportError:
                def get_message(key, **kwargs):
                    fallback_messages = {
                        "processing_summary_title": "ðŸ“‹ Processing Summary",
                        "total_documents_processed": "Total Documents Processed: {count}",
                        "successful_extractions": "Successful Extractions: {count}",
                        "failed_extractions": "Failed Extractions: {count}",
                        "total_tables_extracted": "Total Tables Extracted: {count}",
                        "output_file": "Output File: {path}",
                        "report_file": "Report File: {path}"
                    }
                    message = fallback_messages.get(key, key)
                    return message.format(**kwargs) if kwargs and isinstance(message, str) else message
            
            print("\n" + "=" * 50)
            print(get_message("processing_summary_title"))
            print("=" * 50)
            print(get_message("total_documents_processed", count=self.total_documents_processed))
            print(get_message("successful_extractions", count=self.processing_stats['successful_extractions']))
            
            if self.processing_stats["failed_extractions"] > 0:
                print(get_message("failed_extractions", count=self.processing_stats['failed_extractions']))
            
            print(get_message("total_tables_extracted", count=self.processing_stats['total_tables_extracted']))
            
            # æ˜¾ç¤ºå„è¡¨è®°å½•æ•°
            for table_name, data in self.merged_data.items():
                if data:
                    print(f"{table_name}: {len(data)} records")
            
            print(get_message("output_file", path=output_path))
            print(get_message("report_file", path=report_path))
            print("=" * 50)
            
        except Exception as e:
            print(f"Warning: Failed to generate processing report: {e}")
    
    def merge_results_from_state(self, state_file: str, output_dir: str = ".", 
                                final_output_prefix: str = "final_extraction_results",
                                backup_individual: bool = True) -> Dict[str, Any]:
        """ä»ŽçŠ¶æ€æ–‡ä»¶æ¢å¤å¹¶åˆå¹¶ç»“æžœ / Merge results from state file"""
        try:
            print(f"ðŸ”„ Loading state from: {state_file}")
            
            with open(state_file, 'r', encoding='utf-8') as f:
                state = json.load(f)
            
            temp_dir = state.get("temp_dir")
            if not temp_dir or not os.path.exists(temp_dir):
                raise Exception(f"Temporary directory not found: {temp_dir}")
            
            print(f"ðŸ“ Found temporary directory: {temp_dir}")
            
            # æž„å»ºé…ç½®
            config = {
                "paths": {
                    "output_folder": output_dir,
                    "output_filename": f"{final_output_prefix}.xlsx"
                }
            }
            
            # æ‰§è¡Œåˆå¹¶
            output_path = self.merge_batch_results(temp_dir, config)
            
            # å¤‡ä»½ä¸ªåˆ«æ–‡ä»¶ï¼ˆå¦‚æžœéœ€è¦ï¼‰
            backup_info = {}
            if backup_individual:
                backup_info = self._backup_individual_files(temp_dir, output_dir)
            
            return {
                "excel_merge": {
                    "success": True,
                    "output_path": output_path,
                    "total_documents": self.total_documents_processed
                },
                "backup_info": backup_info,
                "processing_stats": self.processing_stats
            }
            
        except Exception as e:
            print(get_message("system_error", error=str(e)))
            return {
                "excel_merge": {
                    "success": False,
                    "error": str(e)
                }
            }
    
    def _backup_individual_files(self, temp_dir: str, output_dir: str) -> Dict[str, Any]:
        """å¤‡ä»½ä¸ªåˆ«æ‰¹æ¬¡æ–‡ä»¶ / Backup individual batch files"""
        try:
            import shutil
            from datetime import datetime
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            date_folder = datetime.now().strftime("%Y-%m-%d")
            
            # åˆ›å»ºç»“æž„åŒ–çš„å¤‡ä»½ç›®å½•
            backup_dir = os.path.join(output_dir, date_folder, "batch_results", f"batch_backups_{timestamp}")
            Path(backup_dir).mkdir(parents=True, exist_ok=True)
            
            batch_files = list(Path(temp_dir).glob("batch_*_results.xlsx"))
            backed_up_files = []
            
            for batch_file in batch_files:
                backup_path = os.path.join(backup_dir, batch_file.name)
                shutil.copy2(batch_file, backup_path)
                backed_up_files.append(backup_path)
            
            return {
                "backup_directory": backup_dir,
                "backed_up_files": backed_up_files,
                "file_count": len(backed_up_files)
            }
            
        except Exception as e:
            print(f"Warning: Failed to backup individual files: {e}")
            return {"error": str(e)}