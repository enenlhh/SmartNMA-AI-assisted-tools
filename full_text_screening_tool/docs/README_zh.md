# SmartEBM 全文筛选工具 - 完整文档

基于AI驱动的全文筛选工具，在3,292篇全文记录中实现99.9%特异性，具备智能提示词生成、关键词预筛选和系统评价工作流程无缝集成功能。

## 目录

- [研究验证性能](#研究验证性能)
- [核心优势](#核心优势)
- [系统要求](#系统要求)
- [安装指南](#安装指南)
- [配置说明](#配置说明)
- [使用工作流程](#使用工作流程)
- [PICOS提取工作流程](#picos提取工作流程)
- [AI驱动筛选决策](#ai驱动筛选决策)
- [高级功能](#高级功能)
- [性能优化](#性能优化)
- [故障排除](#故障排除)
- [技术架构](#技术架构)
- [与SmartEBM工具集成](#与smartebm工具集成)
- [最佳实践](#最佳实践)

## 研究验证性能

**SmartNMA框架验证**: 本工具在综合验证研究中，对**3,292篇全文记录**实现了**99.9%特异性**，在系统评价工作流程中展现出卓越的准确性。

**关键性能指标**:
- **特异性**: 99.9%（极少假阳性）
- **验证范围**: 3,292篇全文研究论文
- **处理效率**: 智能关键词预筛选减少处理时间
- **决策透明度**: 每个筛选决策的完整审计轨迹和详细推理

## 核心优势

### 智能提示词生成
先进的AI驱动系统，自动生成针对您特定研究标准的筛选提示词，适应研究特征和研究领域以获得最佳准确性。

### 关键词预筛选
智能过滤机制，在完整AI分析之前识别潜在相关研究，显著减少处理时间，同时保持验证的99.9%特异性。

### 透明文档记录
所有筛选决策的完整审计轨迹和详细推理，支持可重现的系统评价并满足循证医学的法规合规要求。

### PICOS框架集成
基于人群、干预、对照、结局和研究设计标准的结构化提取和评估，确保对每篇全文文章的全面系统评估。

### 系统评价工作流程集成
与其他SmartEBM工具和标准系统评价平台无缝连接，支持从文献检索到荟萃分析的端到端自动化。

## 核心功能

### AI驱动全文分析
- **多模型LLM支持**: 配置多个语言模型进行基于共识的筛选决策
- **自适应筛选逻辑**: 智能提示词生成，适应您的特定研究标准
- **置信度评分**: 筛选决策的内置置信度评估
- **质量保证**: 自动验证和错误检测机制

### 高级PDF处理
- **多格式支持**: 处理各种PDF格式，包括扫描文档
- **OCR集成**: 自动文本提取，图像PDF支持OCR备选
- **表格识别**: 可选的表格数据提取和分析
- **页面限制**: 可配置的每个文档最大页数以提高效率

### 并行处理架构
- **可扩展处理**: 大型文档集合的多线程筛选
- **资源管理**: 智能CPU和内存利用
- **容错能力**: 自动重试和恢复机制
- **进度监控**: 实时跟踪和预计完成时间

## 系统要求

### 最低要求
- **Python**: 3.8+（推荐Python 3.10+以获得最佳性能）
- **内存**: 8GB RAM（推荐16GB+用于大型文档集合）
- **CPU**: 4+核心（推荐8+核心用于并行处理）
- **存储**: 2GB+可用空间用于临时文件和输出
- **网络**: 稳定的互联网连接用于LLM API访问

### API要求
- **LLM服务**: OpenAI、Anthropic或兼容的API提供商
- **API密钥**: 有效的API密钥，具有足够的配额用于您的文档量
- **速率限制**: 基于您提供商限制的可配置设置
- **成本管理**: 预算跟踪和监控功能

### 支持格式
- **输入**: PDF文档（基于文本和带OCR的扫描文档）
- **输出**: Excel (.xlsx)、CSV和结构化JSON格式
- **配置**: 基于JSON的配置文件

## 安装指南

### 步骤1: 环境设置

1. **确保安装Python 3.8+**
   ```bash
   python --version  # 应显示3.8或更高版本
   ```

2. **克隆或下载工具**
   ```bash
   git clone <仓库地址>
   cd full_text_screening_tool
   ```

3. **创建虚拟环境（推荐）**
   ```bash
   python -m venv venv
   source venv/bin/activate  # Windows系统: venv\Scripts\activate
   ```

### 步骤2: 安装依赖

```bash
pip install -r requirements.txt
```

**关键依赖**:
- `openai`: LLM API集成
- `pandas`: 数据处理和分析
- `openpyxl`: Excel文件处理
- `PyMuPDF`: PDF文本提取
- `concurrent.futures`: 并行处理支持

### 步骤3: 初始配置

1. **创建配置文件**
   ```bash
   cp config/config_template.json config/config.json
   ```

2. **设置目录结构**
   ```bash
   mkdir -p input output prompts
   ```

3. **验证安装**
   ```bash
   python main.py --help
   ```

## 配置说明

### 基本配置设置

编辑 `config/config.json` 文件，设置您的具体配置：

```json
{
  "paths": {
    "input_folder_path": "input/pdfs",
    "output_excel_path": "output/screening_results.xlsx",
    "prompt_file_path": "prompts/screening_prompt.txt",
    "positive_prompt_file_path": "prompts/positive_prompt.txt",
    "negative_prompt_file_path": "prompts/negative_prompt.txt"
  },
  "llm_configs": {
    "prompt_llm": {
      "api_key": "您的API密钥",
      "base_url": "https://api.openai.com/v1",
      "model": "gpt-4"
    },
    "screening_llms": {
      "Primary_LLM": {
        "api_key": "您的API密钥",
        "base_url": "https://api.openai.com/v1",
        "model": "gpt-4-turbo"
      },
      "Secondary_LLM": {
        "api_key": "您的备用密钥",
        "base_url": "https://api.anthropic.com/v1",
        "model": "claude-3-sonnet"
      }
    }
  },
  "inclusion_criteria": {
    "Study design": "随机对照试验，临床试验",
    "Participants": "患有心血管疾病的成年患者",
    "Intervention": "他汀类治疗或降脂干预",
    "Comparison": "安慰剂、标准护理或其他降脂药物",
    "Outcomes": "心血管事件、死亡率、血脂水平"
  },
  "exclusion_criteria": {
    "Study design": "病例报告、社论、无原始数据的综述",
    "Participants": "儿科人群、动物研究",
    "Language": "非英文出版物"
  }
}
```

### 高级配置选项

#### 并行处理设置
```json
{
  "mode": {
    "screening_mode": "parallel",
    "enable_cost_analysis": true,
    "enable_progress_monitoring": true
  },
  "parallel_settings": {
    "parallel_screeners": 4,
    "auto_distribute": true,
    "retry_failed_batches": true,
    "max_retries": 3,
    "batch_size": 10
  },
  "resource_management": {
    "max_memory_usage": "8GB",
    "api_calls_per_minute": 60,
    "delay_between_screeners": 2
  }
}
```

#### PDF处理配置
```json
{
  "pdf_processing": {
    "max_pages_per_document": 50,
    "enable_ocr": true,
    "extract_tables": false,
    "text_cleaning": true,
    "language_detection": true
  }
}
```

## 使用工作流程

### 方法1: 交互模式（推荐）

```bash
python main.py
```

**交互功能**:
- 语言选择（中文/英文）
- 配置验证
- 实时进度监控
- 错误处理和恢复选项
- 成本估算和跟踪

### 方法2: 命令行界面

```bash
# 使用特定配置开始新筛选
python main.py --config config/config.json --lang zh

# 恢复中断的筛选
python main.py --resume --state-file output/screening_state.json

# 监控运行中的进程
python main.py --monitor --pid 12345

# 清理临时文件
python main.py --cleanup --temp-dir temp_screening
```

### 方法3: 批处理模式

```bash
# 处理特定文件范围
python main.py --start-from 1 --max-files 100

# 使用自定义输出位置处理
python main.py --output-dir results/batch_001

# 启用调试模式进行故障排除
python main.py --debug --verbose
```

## ⚙️ 配置说明

### 主要配置部分

#### 1. 处理模式
```json
{
  "mode": {
    "screening_mode": "parallel",  // "single" 或 "parallel"
    "enable_cost_analysis": true
  }
}
```

#### 2. 文件路径
```json
{
  "paths": {
    "input_folder_path": "/path/to/pdf/files",
    "output_excel_path": "/path/to/results.xlsx",
    "prompt_file_path": "/path/to/screening/prompt.txt"
  }
}
```

#### 3. 并行设置
```json
{
  "parallel_settings": {
    "parallel_screeners": 4,  // 并行工作器数量
    "auto_distribute": true,
    "retry_failed_batches": true,
    "max_retries": 3
  }
}
```

#### 4. LLM配置
```json
{
  "llm_configs": {
    "screening_llms": {
      "LLM_A": {
        "api_key": "your-api-key",
        "base_url": "https://api.provider.com/v1",
        "model": "gpt-4.1-mini"
      }
    }
  }
}
```

#### 5. 筛选标准（PICOS）
```json
{
  "inclusion_criteria": {
    "Study design": "随机对照试验，临床试验",
    "Participants": "具有目标病症的成年人",
    "Intervention": "目标干预措施",
    "Comparison": "安慰剂、对照或比较药物",
    "Outcomes": "主要和次要结局指标"
  }
}
```

## 📊 功能详解

### 并行处理
- **智能分发**: 自动在多个工作器间分发PDF文档
- **负载均衡**: 基于文档大小和复杂度优化处理
- **容错能力**: 失败处理的自动重试和错误恢复
- **资源管理**: 监控内存使用和API速率限制

### PDF处理
- **多格式支持**: 处理各种PDF格式和结构
- **文本提取**: 使用PyMuPDF，扫描文档支持OCR备选
- **表格提取**: 可选择性提取和处理表格内容
- **页面限制**: 可配置每个文档的最大页数

### 成本分析
- **实时跟踪**: 处理过程中监控API成本
- **详细报告**: 生成综合成本明细
- **多货币**: 支持USD和CNY，自动转换
- **预算警报**: 可选成本阈值和警告

### 进度监控
- **实时更新**: 实时进度指示器和统计信息
- **时间估算**: 计算剩余处理时间
- **性能指标**: 处理速度和效率跟踪
- **可视化仪表板**: 可选的GUI监控（如果可用）

## 📈 性能优化

### 推荐设置
- **CPU核心**: 使用可用CPU核心的50-75%进行并行工作
- **内存**: 为最佳性能分配每个工作器2GB+内存
- **API限制**: 根据提供商的速率限制进行配置
- **批次大小**: 根据文档大小和复杂度调整

### 最佳实践
1. **文档准备**: 确保PDF在可能的情况下是可文本搜索的
2. **筛选标准**: 在PICOS标准中要具体和详细
3. **模型选择**: 为prompt生成和筛选使用适当的模型
4. **资源监控**: 在大批量处理期间监控系统资源

## 🔧 故障排除

### 常见问题

#### 1. 导入错误
```bash
# 解决方案：安装缺失的依赖
pip install -r requirements.txt
```

#### 2. PDF处理错误
- 确保PDF没有损坏或设置密码保护
- 检查文件权限和可访问性
- 验证PDF格式兼容性

#### 3. API速率限制
- 在配置中调整 `api_calls_per_minute_limit`
- 增加API调用之间的延迟
- 考虑使用多个API密钥

#### 4. 内存问题
- 减少 `parallel_screeners` 数量
- 降低 `max_pages_per_document`
- 启用文本清理和优化

### 日志文件
- 查看输出目录中的详细错误日志
- 启用调试模式以获得详细日志记录
- 查看成本分析报告了解API使用模式

## 📚 高级用法

### 自定义筛选提示词
为专业领域创建自定义筛选提示词：
1. 为您的特定标准创建提示词文件
2. 包含正面和负面示例
3. 首先用小文档集进行测试
4. 根据筛选准确性进行迭代

### 多模型共识
配置多个LLM进行基于共识的决策：
1. 在 `screening_llms` 中添加多个模型
2. 系统将比较输出
3. 共识提高准确性
4. 对关键系统评价有用

### 与其他工具集成
- 将结果导出到参考文献管理器（EndNote、Zotero）
- 从文献数据库导入
- 连接系统评价平台
- 与统计分析工具集成

## 🤝 贡献

我们欢迎贡献！请查看我们的贡献指南以获取更多信息。

## 📄 许可证

本项目在MIT许可证下授权 - 有关详细信息，请参阅LICENSE文件。

## 🆘 支持

获取支持和问题：
- 在GitHub上创建问题
- 查看 `docs/` 文件夹中的文档
- 查看配置示例
- 联系开发团队

## 🔄 更新

此工具正在积极维护和更新。检查：
- 新的LLM模型支持
- 性能改进
- 错误修复和安全更新
- 功能增强

---

**注意**：此工具需要LLM服务的有效API密钥。在大规模使用之前，请确保您有适当的访问权限并了解相关费用。## PI
COS提取工作流程

该工具实现了全文筛选的综合两阶段流程：

### 阶段1: 结构化PICOS提取

**人群 (Population)**: 提取详细的参与者特征，包括：
- 人口统计学特征（年龄、性别、种族）
- 医疗条件和严重程度
- 研究中使用的纳入/排除标准
- 样本量和招募环境
- 基线特征和合并症

**干预 (Intervention)**: 捕获全面的干预详情：
- 具体治疗方案和剂量
- 干预的持续时间和频率
- 给药方法和实施环境
- 联合干预和组合治疗
- 干预依从性和坚持性措施

**对照 (Comparison)**: 记录对照和比较组：
- 安慰剂特征和盲法方法
- 活性对照详情和剂量
- 标准护理方案和指南
- 无治疗或等待名单对照描述
- 历史或外部对照规格

**结局 (Outcomes)**: 识别所有测量终点：
- 主要结局和测量方法
- 次要结局和探索性终点
- 安全性结局和不良事件
- 时间点和随访持续时间
- 结局评估工具和验证

**研究设计 (Study Design)**: 确定精确的研究方法：
- 随机化方法和分配隐藏
- 盲法程序（单盲、双盲、三盲）
- 平行组与交叉设计
- 多中心与单中心研究
- 适应性设计和中期分析

### 阶段2: 纳入评估

**系统评估**: 使用完整的全文信息，根据您预定义的纳入和排除标准系统评估每个PICOS要素。

**决策框架**:
- **纳入**: 研究满足所有纳入标准且不满足任何排除标准
- **排除**: 研究不满足任何纳入标准或满足任何排除标准
- **不明确**: 信息不足（在全文筛选中很少见）

**推理文档**: 每个决策都包含详细解释，引用满足或未满足的具体标准，支持审计轨迹和可重现性。

## AI驱动筛选决策

### 智能提示词生成

系统根据您的研究标准自动生成定制的筛选提示词：

1. **标准分析**: 分析您的纳入/排除标准以理解研究重点
2. **领域适应**: 适应您特定医学/研究领域的语言和示例
3. **提示词优化**: 创建针对准确性和一致性优化的提示词
4. **验证集成**: 整合从99.9%特异性验证中学到的经验

### 多模型共识筛选

**双提示词验证**: 使用略有不同的提示词变体测试决策一致性：
- **综合评估提示词**: 强调全面系统评估
- **精确聚焦提示词**: 强调精确要求验证
- **共识分析**: 比较结果以识别潜在边缘案例

**多LLM支持**: 配置多个语言模型以增强可靠性：
- **主要筛选**: 使用您首选的高准确性模型
- **验证筛选**: 次要模型用于共识验证
- **冲突解决**: 自动处理模型间的分歧

### 关键词预筛选

**智能过滤**: 在完整AI分析之前，系统：
1. **提取关键术语**: 从您的标准中识别领域特定术语
2. **内容扫描**: 快速扫描全文中的相关关键词和概念
3. **相关性评分**: 基于关键词密度分配初步相关性分数
4. **高效处理**: 优先处理可能相关的文档进行详细AI分析

**性能优势**:
- 在保持99.9%特异性的同时减少40-60%的处理时间
- 识别明显不相关的研究而无需昂贵的LLM调用
- 保持预筛选决策的完整审计轨迹

## 高级功能

### 并行处理架构

**智能资源管理**:
- **CPU利用**: 自动检测可用核心并优化工作器分配
- **内存管理**: 监控RAM使用并动态调整批次大小
- **API速率限制**: 通过智能请求间隔尊重提供商限制
- **负载均衡**: 基于大小和复杂性分发文档

**容错能力**:
- **检查点恢复**: 自动保存进度并具有恢复功能
- **错误处理**: 优雅处理API故障、网络问题和损坏文件
- **重试逻辑**: 可配置的重试次数和指数退避
- **状态管理**: 长时间运行进程的持久状态跟踪

### 成本分析和优化

**实时成本跟踪**:
- **令牌使用监控**: 跟踪每个文档的提示词和完成令牌
- **多货币支持**: 显示USD、EUR、GBP、CNY和JPY的成本
- **预算警报**: 可配置的支出阈值和自动通知
- **成本优化**: 模型选择和批次大小的建议

**详细报告**:
- **每文档成本**: 每篇筛选文章的个别成本明细
- **模型比较**: 不同LLM的成本和性能分析
- **效率指标**: 处理速度和每文档成本分析
- **导出选项**: 用于财务跟踪的CSV和Excel报告

### 质量保证框架

**验证机制**:
- **响应格式验证**: 确保所有输出遵循所需的PICOS结构
- **一致性检查**: 识别筛选决策中的潜在不一致性
- **置信度评分**: 决策可靠性的内置评估
- **人工审查集成**: 标记不确定案例进行人工审查

**审计轨迹**:
- **完整文档**: 所有筛选决策和推理的完整记录
- **时间戳跟踪**: 每个处理步骤的精确时间信息
- **版本控制**: 跟踪提示词版本和配置更改
- **可重现性**: 重现结果所需的完整信息

## 性能优化

### 推荐系统配置

**小型集合（< 100个文档）**:
- **CPU**: 最少4核
- **RAM**: 最少8GB
- **并行工作器**: 2-3个工作器
- **预期处理**: 每小时10-20个文档

**中型集合（100-1000个文档）**:
- **CPU**: 推荐8+核
- **RAM**: 推荐16GB
- **并行工作器**: 4-6个工作器
- **预期处理**: 每小时30-50个文档

**大型集合（1000+个文档）**:
- **CPU**: 最佳12+核
- **RAM**: 最佳32GB
- **并行工作器**: 6-8个工作器
- **预期处理**: 每小时50-80个文档

### LLM模型选择指南

**最大准确性**:
- **主要**: GPT-4或Claude-3-Opus用于复杂筛选标准
- **次要**: GPT-4-Turbo用于验证和共识
- **成本**: 每文档成本较高，但可靠性最大

**平衡性能**:
- **主要**: GPT-4-Turbo或Claude-3-Sonnet用于大多数筛选任务
- **次要**: GPT-3.5-Turbo用于验证
- **成本**: 中等成本，准确性优秀

**大批量处理**:
- **主要**: GPT-3.5-Turbo或Claude-3-Haiku用于直接标准
- **次要**: 相同模型保持一致性
- **成本**: 每文档成本较低，适合明确标准

## 故障排除

### 常见问题和解决方案

#### 安装问题

**导入错误**:
```bash
# 解决方案：重新安装依赖
pip uninstall -r requirements.txt -y
pip install -r requirements.txt
```

**权限错误**:
```bash
# 解决方案：检查文件权限
chmod +x main.py
chmod -R 755 input output
```

#### 配置问题

**API密钥问题**:
- 验证API密钥有效且有足够配额
- 检查基础URL与您提供商的端点匹配
- 确保指定的模型在您的账户中可用

**路径配置**:
- 对输入和输出目录使用绝对路径
- 确保所有指定目录存在且可写
- 检查配置文件的文件权限

#### 处理错误

**PDF读取失败**:
- 验证PDF没有密码保护或损坏
- 在配置中为扫描文档启用OCR
- 检查临时文件的可用磁盘空间

**内存问题**:
- 在配置中减少并行工作器数量
- 减少大文档的批次大小
- 启用文本清理以减少内存使用

**API速率限制**:
- 在配置中增加API调用之间的延迟
- 减少并行工作器数量
- 考虑使用多个API密钥以获得更高吞吐量

### 调试模式

启用详细日志记录进行故障排除：

```bash
python main.py --debug --verbose --log-file debug.log
```

**调试功能**:
- **详细日志记录**: 所有操作的完整跟踪
- **API请求/响应**: 完整的LLM交互日志
- **性能指标**: 时间和资源使用统计
- **错误堆栈跟踪**: 用于诊断的完整错误信息

## 技术架构

### 核心组件

**主入口点 (`main.py`)**:
- 命令行界面和参数解析
- 配置加载和验证
- 进程编排和错误处理
- 交互模式和用户界面

**全文提取器 (`src/fulltext_extractor.py`)**:
- PICOS提取和筛选逻辑
- LLM客户端管理和API交互
- 提示词生成和优化
- 响应解析和验证

**文档读取器 (`src/document_reader.py`)**:
- 多种备选方法的PDF文本提取
- 扫描文档的OCR集成
- 文本预处理和清理
- 元数据提取和验证

**并行控制器 (`core/parallel_controller.py`)**:
- 多线程处理协调
- 资源管理和负载均衡
- 错误处理和恢复机制
- 进度监控和报告

### 数据流架构

```
输入PDF → 文档读取器 → 文本提取 → PICOS分析 → 筛选决策 → 结果导出
    ↓         ↓         ↓         ↓         ↓         ↓
文件验证 → OCR处理 → 预处理 → LLM处理 → 验证 → Excel/CSV输出
    ↓         ↓         ↓         ↓         ↓         ↓
错误处理 → 重试逻辑 → 质量检查 → 共识检查 → 审计轨迹 → 成本分析
```

### 集成点

**输入接口**:
- PDF文档集合
- 配置文件（JSON）
- 自定义筛选标准
- API凭据和设置

**输出接口**:
- 带PICOS数据的结构化Excel报告
- 用于统计分析的CSV文件
- 用于程序访问的JSON导出
- 成本分析报告

**外部依赖**:
- OpenAI API或兼容的LLM服务
- PyMuPDF用于PDF处理
- Pandas用于数据操作
- OpenPyXL用于Excel文件生成

## 与SmartEBM工具集成

### 上游集成

**来自文献检索工具**:
- **输入格式**: 来自数据库检索的PDF集合
- **元数据保存**: 研究标识符和检索词
- **质量指标**: 初始相关性分数和来源数据库

**来自题录/摘要筛选**:
- **过滤集合**: 预筛选的文档集
- **筛选历史**: 先前的筛选决策和置信度分数
- **纳入理由**: 推进到全文筛选的原因

### 下游集成

**到数据提取工具**:
- **纳入研究**: 相关全文文章的过滤集合
- **PICOS数据**: 用于提取模板的结构化研究特征
- **质量元数据**: 筛选置信度和决策理由

**到偏倚风险评估**:
- **研究设计信息**: 筛选期间提取的详细方法学
- **质量指标**: 研究质量和报告的初始评估
- **偏倚风险标志**: 筛选期间识别的潜在偏倚来源

**到统计分析工具**:
- **研究特征**: 用于亚组分析的人群和干预详情
- **结局信息**: 用于荟萃分析规划的终点数据
- **纳入标准**: PRISMA报告的系统文档

### 工作流程集成示例

**完整系统评价流程**:
1. **文献检索** → 数据库检索结果（PDF）
2. **题录/摘要筛选** → 潜在相关研究
3. **全文筛选**（本工具）→ 带PICOS数据的纳入研究
4. **数据提取** → 用于分析的定量数据
5. **偏倚风险评估** → 质量评估
6. **统计分析** → 荟萃分析结果
7. **GRADE评估** → 证据质量评级

**质量保证工作流程**:
- **双重筛选**: 多个审查员的独立筛选
- **共识解决**: 自动冲突识别和解决
- **审计轨迹**: 法规合规的完整文档
- **可重现性**: 版本控制的配置和结果

## 最佳实践

### 筛选标准制定

**特异性指南**:
- 为每个PICOS要素定义清晰、可测量的纳入标准
- 使用具体术语而非广泛类别
- 包含边界案例示例和处理方法
- 在完整筛选前用小样本测试标准

**排除标准**:
- 明确什么构成排除
- 考虑分层排除（主要vs次要原因）
- 记录每个排除标准的理由
- 平衡特异性与实际筛选效率

### 质量控制程序

**预筛选验证**:
- 用10-20个代表性文档测试配置
- 与领域专家验证提示词生成
- 检查输出格式和完整性
- 验证成本估算和处理时间

**筛选期间**:
- 定期监控进度和错误率
- 审查不确定决策和边缘案例
- 跟踪预算的成本累积
- 维护备份配置和检查点

**筛选后审查**:
- 对筛选决策进行样本验证
- 审查排除研究的潜在假阴性
- 分析成本和效率指标
- 记录未来筛选的经验教训

### 性能优化

**配置调优**:
- 从保守的并行设置开始，逐步增加
- 处理期间监控系统资源
- 根据文档复杂性调整批次大小
- 根据准确性要求使用适当模型

**成本管理**:
- 基于文档量设定现实预算
- 在完整处理前使用成本估算功能
- 根据筛选复杂性考虑模型选择
- 处理期间实时监控支出

**错误预防**:
- 开始前验证所有文件路径和权限
- 测试API连接和速率限制
- 确保临时文件有足够磁盘空间
- 为关键筛选创建备份配置

---

## 支持和维护

### 获取帮助

**文档资源**:
- `config/` 目录中的完整配置示例
- 常见研究领域的样本筛选标准
- 常见问题的故障排除指南
- 性能优化建议

**社区支持**:
- GitHub问题用于错误报告和功能请求
- 方法学问题的讨论论坛
- 示例配置和用例
- 最佳实践分享和协作

### 更新和维护

**定期更新**:
- 新LLM模型支持和优化
- 性能改进和错误修复
- 与其他SmartEBM工具的增强集成
- 安全更新和依赖管理

**版本兼容性**:
- 配置文件的向后兼容性
- 主要版本更新的迁移指南
- 过时功能的弃用通知
- 新安装的测试程序

---

**注意**: 此工具需要LLM服务的有效API密钥，可能会根据使用情况产生费用。始终先用小文档集进行测试，并在大规模处理期间监控成本。99.9%特异性验证是在受控研究条件下实现的；实际性能可能因您的具体标准和文档特征而异。