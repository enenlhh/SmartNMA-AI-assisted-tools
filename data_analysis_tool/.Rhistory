# 优先判断为分类型，因为连续型和分类型都有sampleSize
is_continuous <- has_continuous_cols && !has_categorical_cols
# 创建新的列名映射
new_col_mapping <- data.frame(
original = col_names,
new = col_names,
stringsAsFactors = FALSE
)
# 遍历所有列名，映射到gemtc需要的列名
for(i in 1:nrow(new_col_mapping)) {
orig_col <- new_col_mapping$original[i]
# 检查通用列名映射
for(j in names(column_mapping$general)) {
if(tolower(orig_col) == tolower(j)) {
new_col_mapping$new[i] <- column_mapping$general[j]
break
}
}
# 如果是连续型结局，检查连续型列名映射
if(is_continuous) {
for(j in names(column_mapping$continuous)) {
if(tolower(orig_col) == tolower(j)) {
new_col_mapping$new[i] <- column_mapping$continuous[j]
break
}
}
} else {
# 如果是分类型结局，检查分类型列名映射
for(j in names(column_mapping$categorical)) {
if(tolower(orig_col) == tolower(j)) {
new_col_mapping$new[i] <- column_mapping$categorical[j]
break
}
}
}
}
# 重命名列
for(i in 1:nrow(new_col_mapping)) {
if(new_col_mapping$original[i] != new_col_mapping$new[i]) {
colnames(raw_data)[which(colnames(raw_data) == new_col_mapping$original[i])] <- new_col_mapping$new[i]
}
}
# 检查必要的列是否存在
if(is_continuous) {
required_cols <- c("study", "treatment", "sampleSize", "mean", "std.dev")
} else {
required_cols <- c("study", "treatment", "responders", "sampleSize")
}
missing_cols <- setdiff(required_cols, colnames(raw_data))
if(length(missing_cols) > 0) {
stop("缺少必要的列: ", paste(missing_cols, collapse = ", "))
}
# 提取分析数据，只对study和treatment列进行文本清理
analysis_data <- raw_data %>%
select(all_of(required_cols))
# 只对study和treatment列应用清理函数
analysis_data$study <- sapply(analysis_data$study, clean_text)
analysis_data$treatment <- sapply(analysis_data$treatment, clean_text)
# 提取潜在的变量数据 (非required_cols的列)
possible_variable_cols <- setdiff(colnames(raw_data), required_cols)
if(length(possible_variable_cols) > 0) {
# 提取变量数据，并按study去重
factor_data <- raw_data %>%
select(study, all_of(possible_variable_cols)) %>%
distinct(study, .keep_all = TRUE) # 去重
# 对study列和变量因素表的列名应用清理函数
factor_data$study <- sapply(factor_data$study, clean_text)
for(col in setdiff(colnames(factor_data), "study")) {
factor_data[[col]] <- sapply(factor_data[[col]], clean_text)
}
} else {
# 如果没有变量列，创建一个只有study列的因子数据框
factor_data <- raw_data %>%
select(study) %>%
distinct() # 确保study唯一
# 对study列应用清理函数
factor_data$study <- sapply(factor_data$study, clean_text)
}
# SE转换为SD（如果有的话）
if(is_continuous && "std.error" %in% colnames(analysis_data)) {
analysis_data <- analysis_data %>%
mutate(std.dev = std.error * sqrt(sampleSize)) %>%
select(-std.error)
}
# 保存为csv文件
analysis_file <- file.path(output_dir, paste0(outcome_name, "_data.csv"))
factor_file <- file.path(output_dir, paste0(outcome_name, "_factor.csv"))
write.csv(analysis_data, analysis_file, row.names = FALSE)
write.csv(factor_data, factor_file, row.names = FALSE)
cat("数据处理完成，已保存到:", analysis_file, "和", factor_file, "\n")
# 进行网状Meta回归分析
data <- read.csv(analysis_file, header = TRUE)
factor <- read.csv(factor_file, header = TRUE)
# 获取所有的变量名称（除了study）
variables <- setdiff(colnames(factor), "study")
# 获取所有treatment名称
treatments <- unique(data$treatment)
# 调试：打印控制组和处理列表
cat("控制组:", control_treatment, "\n")
cat("处理列表:", treatments, "\n")
# 检查用户指定的控制组是否存在
if(!(control_treatment %in% treatments)) {
warning("用户指定的控制组'", control_treatment, "'不在数据集中的处理列表中。使用第一个处理作为控制组。")
control_treatment <- treatments[1]
}
# 对每个变量进行回归分析
for(variable in variables) {
tryCatch({
cat("正在对结局", outcome_name, "进行", variable, "的网状Meta回归分析\n")
# 拷贝数据，以便对特定变量进行处理
factor_for_var <- factor
# 检查变量值是否为非数值（包括NA、NR等）
is_numeric_var <- !is.na(suppressWarnings(as.numeric(factor_for_var[[variable]])))
# 如果有非数值的研究，需要剔除
if(any(!is_numeric_var)) {
non_numeric_studies <- factor_for_var$study[!is_numeric_var]
cat("警告：在变量", variable, "中发现非数值的研究:",
paste(non_numeric_studies, collapse = ", "), "将从分析中剔除。\n")
# 过滤因子数据表，只保留变量值为数值的研究
factor_for_var <- factor_for_var[is_numeric_var, ]
# 过滤分析数据表，只保留变量值为数值的研究
data_for_var <- data[!data$study %in% non_numeric_studies, ]
} else {
# 如果所有变量值都是数值，直接使用完整数据
data_for_var <- data
}
# 将变量转换为数值类型
factor_for_var[[variable]] <- as.numeric(factor_for_var[[variable]])
# 检查剩余的数据是否足够进行分析
if(nrow(factor_for_var) == 0 || nrow(data_for_var) == 0) {
cat("错误：剔除非数值研究后，没有足够的数据进行分析。\n")
next
}
# 创建网络
network <- mtc.network(data = data_for_var, studies = factor_for_var)
# 创建回归模型
if (is_continuous) {
reg_model <- mtc.model(network, type = "regression",
regressor = list(coefficient = 'shared',
variable = variable,
control = control_treatment),
om.scale = NULL, linearModel = "random", n.chain = 3)
} else {
reg_model <- mtc.model(network, type = "regression", likelihood = likelihood, link = link,
regressor = list(coefficient = 'shared',
variable = variable,
control = control_treatment),
om.scale = NULL, linearModel = "random", n.chain = 3)
}
# 运行模型
results <- mtc.run(reg_model, n.adapt = 50000, n.iter = 100000, thin = 1)
# 计算相对效应并生成摘要
relative_effect_summary <- summary(relative.effect(results, control_treatment))
summary_text <- capture.output(relative_effect_summary)
results_file_txt <- file.path(output_dir, paste0(outcome_name, "_", variable, "_regression_summary.txt"))
writeLines(summary_text, results_file_txt)
cat("已保存 relative_effect_summary 到:", results_file_txt, "\n")
# 制作列联表
mtc_results <- as.data.frame(round((relative.effect.table(results)), 2))
# 保存结果
results_file <- file.path(output_dir, paste0(outcome_name, "_", variable, "_regression.csv"))
write.csv(mtc_results, file = results_file)
# 生成所有处理对比的图
for(treatment in setdiff(unique(data_for_var$treatment), control_treatment)) {
plot_file <- file.path(output_dir, paste0(outcome_name, "_", variable, "_", treatment, ".pdf"))
pdf(plot_file, width = 8, height = 5)
plotCovariateEffect(results, t1 = control_treatment, t2 = c(treatment),
ask = dev.interactive(orNone = TRUE))
dev.off()
}
cat("完成", variable, "的网状Meta回归分析\n")
}, error = function(e) {
cat("在处理", variable, "时出错:", e$message, "\n")
})
}
cat("已完成结局", outcome_name, "的所有网状Meta回归分析\n\n")
}, error = function(e) {
cat("处理文件", file, "时出错:", e$message, "\n")
})
}
cat("所有结局的网状Meta回归分析已完成！\n")
rm(list = ls())  # 清除所有对象
is_windows <- .Platform$OS.type == "windows"
# 加载必要的库
library(gemtc)
library(readxl)
library(dplyr)
library(stringr)
library(tidyr)
library(openxlsx)
# 路径设置 - 根据操作系统自动选择
if (is_windows) {
# Windows 路径
input_dir <- "C:/Users/Laihh/OneDrive/Personality researches/MARS-NMA/自动meta回归/Test/回归数据1"
output_dir <- "C:/Users/Laihh/OneDrive/Personality researches/MARS-NMA/自动meta回归/Test/回归结果1"
} else {
# macOS 路径
input_dir <- '/Users/honghaolai/Downloads/Low ROB_22.July_25/gemtc 补78'
output_dir <- '/Users/honghaolai/Downloads/Low ROB_22.July_25/gemtc results'
}
# 用户指定控制组
control_treatment <- "Minimal_intervention"
# 用户指定分类变量的效应值类型
effect_type <- "RR"  # 用户输入：RR、OR或HR
# 根据效应值类型设置likelihood和link
if (effect_type == "RR") {
likelihood <- "binom"
link <- "log"
} else if (effect_type == "OR") {
likelihood <- "binom"
link <- "logit"
} else if (effect_type == "HR") {
likelihood <- "poisson"
link <- "log"
} else {
stop("无效的效应值类型。请输入RR、OR或HR。")
}
# 创建输出目录（如果不存在）
if(!dir.exists(output_dir)) {
dir.create(output_dir, recursive = TRUE)
}
# 获取所有xlsx文件
xlsx_files <- list.files(path = input_dir, pattern = "*.xlsx", full.names = TRUE)
# 清理文本，替换特殊字符和空格为下划线，但保留数值、逗号和小数点
clean_text <- function(text) {
# 检查是否为数值（包括负数和小数）
is_numeric <- !is.na(suppressWarnings(as.numeric(text)))
if(is_numeric) {
# 如果是数值，直接返回
return(text)
} else {
# 如果不是数值，进行清理
# 替换非字母、数字、逗号、小数点、下划线的字符为下划线
text <- str_replace_all(text, "[^a-zA-Z0-9,\\._]", "_")
# 替换多个连续下划线为单个下划线
text <- str_replace_all(text, "_{2,}", "_")
# 去除首尾的下划线
text <- str_replace_all(text, "^_|_$", "")
return(text)
}
}
# 清理列名，替换空格为下划线
clean_colnames <- function(df) {
colnames(df) <- str_replace_all(colnames(df), " ", "_")
return(df)
}
# 定义列名映射（从原始列名到gemtc所需列名）
column_mapping <- list(
# 连续性结局
continuous = c(
"mean" = "mean",
"Mean" = "mean",
"MEAN" = "mean",
"sd" = "std.dev",
"SD" = "std.dev",
"std.dev" = "std.dev",
"std" = "std.dev",
"STD" = "std.dev",
"std_dev" = "std.dev",
"std.error" = "std.dev",
"SE" = "std.dev",
"se" = "std.dev",
"n" = "sampleSize",
"N" = "sampleSize",
"sample" = "sampleSize",
"sample_size" = "sampleSize",
"Sample_Size" = "sampleSize",
"sampleSize" = "sampleSize"
),
# 分类性结局
categorical = c(
"event" = "responders",
"events" = "responders",
"Event" = "responders",
"Events" = "responders",
"responders" = "responders",
"Responders" = "responders",
"r" = "responders",
"R" = "responders",
"n" = "sampleSize",
"N" = "sampleSize",
"total" = "sampleSize",
"Total" = "sampleSize",
"sample" = "sampleSize",
"Sample" = "sampleSize",
"sample_size" = "sampleSize",
"Sample_Size" = "sampleSize",
"sampleSize" = "sampleSize"
),
# 通用列名
general = c(
"study" = "study",
"Study" = "study",
"STUDY" = "study",
"id" = "study",
"ID" = "study",
"treatment" = "treatment",
"Treatment" = "treatment",
"TREATMENT" = "treatment",
"arm" = "treatment",
"Arm" = "treatment",
"ARM" = "treatment",
"intervention" = "treatment",
"Intervention" = "treatment"
)
)
# 处理每个文件
for(file in xlsx_files) {
tryCatch({
# 提取结局名称（文件名，不含扩展名）
outcome_name <- tools::file_path_sans_ext(basename(file))
cat("正在处理结局:", outcome_name, "\n")
# 读取Excel文件
raw_data <- read_excel(file)
# 清理列名中的空格
raw_data <- clean_colnames(raw_data)
# 更新列名映射字典，考虑列名中已经有下划线的情况
for(category in names(column_mapping)) {
new_mapping <- column_mapping[[category]]
new_names <- names(new_mapping)
new_names_clean <- str_replace_all(new_names, " ", "_")
names(new_mapping) <- new_names_clean
column_mapping[[category]] <- new_mapping
}
# 确定结局类型（连续型或分类型）
col_names <- colnames(raw_data)
has_continuous_cols <- any(sapply(names(column_mapping$continuous), function(x)
tolower(x) %in% tolower(col_names)))
has_categorical_cols <- any(sapply(names(column_mapping$categorical), function(x)
tolower(x) %in% tolower(col_names) &&
!(tolower(x) %in% c("n", "sample", "samplesize", "sample_size"))))
# 优先判断为分类型，因为连续型和分类型都有sampleSize
is_continuous <- has_continuous_cols && !has_categorical_cols
# 创建新的列名映射
new_col_mapping <- data.frame(
original = col_names,
new = col_names,
stringsAsFactors = FALSE
)
# 遍历所有列名，映射到gemtc需要的列名
for(i in 1:nrow(new_col_mapping)) {
orig_col <- new_col_mapping$original[i]
# 检查通用列名映射
for(j in names(column_mapping$general)) {
if(tolower(orig_col) == tolower(j)) {
new_col_mapping$new[i] <- column_mapping$general[j]
break
}
}
# 如果是连续型结局，检查连续型列名映射
if(is_continuous) {
for(j in names(column_mapping$continuous)) {
if(tolower(orig_col) == tolower(j)) {
new_col_mapping$new[i] <- column_mapping$continuous[j]
break
}
}
} else {
# 如果是分类型结局，检查分类型列名映射
for(j in names(column_mapping$categorical)) {
if(tolower(orig_col) == tolower(j)) {
new_col_mapping$new[i] <- column_mapping$categorical[j]
break
}
}
}
}
# 重命名列
for(i in 1:nrow(new_col_mapping)) {
if(new_col_mapping$original[i] != new_col_mapping$new[i]) {
colnames(raw_data)[which(colnames(raw_data) == new_col_mapping$original[i])] <- new_col_mapping$new[i]
}
}
# 检查必要的列是否存在
if(is_continuous) {
required_cols <- c("study", "treatment", "sampleSize", "mean", "std.dev")
} else {
required_cols <- c("study", "treatment", "responders", "sampleSize")
}
missing_cols <- setdiff(required_cols, colnames(raw_data))
if(length(missing_cols) > 0) {
stop("缺少必要的列: ", paste(missing_cols, collapse = ", "))
}
# 提取分析数据，只对study和treatment列进行文本清理
analysis_data <- raw_data %>%
select(all_of(required_cols))
# 只对study和treatment列应用清理函数
analysis_data$study <- sapply(analysis_data$study, clean_text)
analysis_data$treatment <- sapply(analysis_data$treatment, clean_text)
# 提取潜在的变量数据 (非required_cols的列)
possible_variable_cols <- setdiff(colnames(raw_data), required_cols)
if(length(possible_variable_cols) > 0) {
# 提取变量数据，并按study去重
factor_data <- raw_data %>%
select(study, all_of(possible_variable_cols)) %>%
distinct(study, .keep_all = TRUE) # 去重
# 对study列和变量因素表的列名应用清理函数
factor_data$study <- sapply(factor_data$study, clean_text)
for(col in setdiff(colnames(factor_data), "study")) {
factor_data[[col]] <- sapply(factor_data[[col]], clean_text)
}
} else {
# 如果没有变量列，创建一个只有study列的因子数据框
factor_data <- raw_data %>%
select(study) %>%
distinct() # 确保study唯一
# 对study列应用清理函数
factor_data$study <- sapply(factor_data$study, clean_text)
}
# SE转换为SD（如果有的话）
if(is_continuous && "std.error" %in% colnames(analysis_data)) {
analysis_data <- analysis_data %>%
mutate(std.dev = std.error * sqrt(sampleSize)) %>%
select(-std.error)
}
# 保存为csv文件
analysis_file <- file.path(output_dir, paste0(outcome_name, "_data.csv"))
factor_file <- file.path(output_dir, paste0(outcome_name, "_factor.csv"))
write.csv(analysis_data, analysis_file, row.names = FALSE)
write.csv(factor_data, factor_file, row.names = FALSE)
cat("数据处理完成，已保存到:", analysis_file, "和", factor_file, "\n")
# 进行网状Meta回归分析
data <- read.csv(analysis_file, header = TRUE)
factor <- read.csv(factor_file, header = TRUE)
# 获取所有的变量名称（除了study）
variables <- setdiff(colnames(factor), "study")
# 获取所有treatment名称
treatments <- unique(data$treatment)
# 调试：打印控制组和处理列表
cat("控制组:", control_treatment, "\n")
cat("处理列表:", treatments, "\n")
# 检查用户指定的控制组是否存在
if(!(control_treatment %in% treatments)) {
warning("用户指定的控制组'", control_treatment, "'不在数据集中的处理列表中。使用第一个处理作为控制组。")
control_treatment <- treatments[1]
}
# 对每个变量进行回归分析
for(variable in variables) {
tryCatch({
cat("正在对结局", outcome_name, "进行", variable, "的网状Meta回归分析\n")
# 拷贝数据，以便对特定变量进行处理
factor_for_var <- factor
# 检查变量值是否为非数值（包括NA、NR等）
is_numeric_var <- !is.na(suppressWarnings(as.numeric(factor_for_var[[variable]])))
# 如果有非数值的研究，需要剔除
if(any(!is_numeric_var)) {
non_numeric_studies <- factor_for_var$study[!is_numeric_var]
cat("警告：在变量", variable, "中发现非数值的研究:",
paste(non_numeric_studies, collapse = ", "), "将从分析中剔除。\n")
# 过滤因子数据表，只保留变量值为数值的研究
factor_for_var <- factor_for_var[is_numeric_var, ]
# 过滤分析数据表，只保留变量值为数值的研究
data_for_var <- data[!data$study %in% non_numeric_studies, ]
} else {
# 如果所有变量值都是数值，直接使用完整数据
data_for_var <- data
}
# 将变量转换为数值类型
factor_for_var[[variable]] <- as.numeric(factor_for_var[[variable]])
# 检查剩余的数据是否足够进行分析
if(nrow(factor_for_var) == 0 || nrow(data_for_var) == 0) {
cat("错误：剔除非数值研究后，没有足够的数据进行分析。\n")
next
}
# 创建网络
network <- mtc.network(data = data_for_var, studies = factor_for_var)
# 创建回归模型
if (is_continuous) {
reg_model <- mtc.model(network, type = "regression",
regressor = list(coefficient = 'shared',
variable = variable,
control = control_treatment),
om.scale = NULL, linearModel = "random", n.chain = 3)
} else {
reg_model <- mtc.model(network, type = "regression", likelihood = likelihood, link = link,
regressor = list(coefficient = 'shared',
variable = variable,
control = control_treatment),
om.scale = NULL, linearModel = "random", n.chain = 3)
}
# 运行模型
results <- mtc.run(reg_model, n.adapt = 50000, n.iter = 100000, thin = 1)
# 计算相对效应并生成摘要
relative_effect_summary <- summary(relative.effect(results, control_treatment))
summary_text <- capture.output(relative_effect_summary)
results_file_txt <- file.path(output_dir, paste0(outcome_name, "_", variable, "_regression_summary.txt"))
writeLines(summary_text, results_file_txt)
cat("已保存 relative_effect_summary 到:", results_file_txt, "\n")
# 制作列联表
mtc_results <- as.data.frame(round((relative.effect.table(results)), 2))
# 保存结果
results_file <- file.path(output_dir, paste0(outcome_name, "_", variable, "_regression.csv"))
write.csv(mtc_results, file = results_file)
# 生成所有处理对比的图
for(treatment in setdiff(unique(data_for_var$treatment), control_treatment)) {
plot_file <- file.path(output_dir, paste0(outcome_name, "_", variable, "_", treatment, ".pdf"))
pdf(plot_file, width = 8, height = 5)
plotCovariateEffect(results, t1 = control_treatment, t2 = c(treatment),
ask = dev.interactive(orNone = TRUE))
dev.off()
}
cat("完成", variable, "的网状Meta回归分析\n")
}, error = function(e) {
cat("在处理", variable, "时出错:", e$message, "\n")
})
}
cat("已完成结局", outcome_name, "的所有网状Meta回归分析\n\n")
}, error = function(e) {
cat("处理文件", file, "时出错:", e$message, "\n")
})
}
cat("所有结局的网状Meta回归分析已完成！\n")
